{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_jobs():\n",
    "    # Initialize an empty DataFrame with predefined columns\n",
    "    df = pd.DataFrame(columns=[\"job_name\", \"company_name\", \"location\", \"job_type\", \"exp_level\", \"exp_years\"])\n",
    "    \n",
    "    # Loop through the pages\n",
    "    for page in range(100):\n",
    "        try:\n",
    "            # Send a GET request to fetch the page content\n",
    "            response = requests.get(f\"https://wuzzuf.net/search/jobs/?a=hpb&q=&start={page}\")\n",
    "            response.raise_for_status()  # Raise an HTTPError for bad responses (4xx and 5xx)\n",
    "            soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "            \n",
    "            # Find all job postings on the page\n",
    "            jobs = soup.find_all(\"div\", class_=\"css-1gatmva e1v1l3u10\")\n",
    "            \n",
    "            for job in jobs:\n",
    "                try:\n",
    "                    # Extract job details\n",
    "                    job_name = job.find(\"h2\", class_=\"css-m604qf\").text.strip()\n",
    "                    company_name = job.find(\"div\", class_=\"css-d7j1kk\").text.split(\" - \")[0].strip()\n",
    "                    location = job.find(\"span\", class_=\"css-5wys0k\").text.split(\", \")[0].strip()\n",
    "                    job_type = job.find(\"span\", class_=\"css-1ve4b75 eoyjyou0\").text.strip()\n",
    "                    exp_details = job.find(\"div\", class_=\"css-1lh32fc\").next_sibling.text.split(\" Â· \")\n",
    "                    exp_level = exp_details[0].strip()\n",
    "                    exp_years = exp_details[1].strip() if len(exp_details) > 1 else \"N/A\"\n",
    "                    \n",
    "                    # Append the job details to the DataFrame\n",
    "                    df.loc[len(df)] = [job_name, company_name, location, job_type, exp_level, exp_years]\n",
    "                except (AttributeError, IndexError) as e:\n",
    "                    # Handle missing or malformed job details\n",
    "                    print(f\"Error parsing job details: {e}\")\n",
    "            # Log progress\n",
    "            print(f\"Page {page} processed successfully.\")\n",
    "        \n",
    "        except requests.RequestException as e:\n",
    "            # Handle request errors\n",
    "            print(f\"Error fetching page {page}: {e}\")\n",
    "    \n",
    "    # Save the scraped data to a CSV file\n",
    "    df.to_csv(\"wuzzuf_jobs_in_egypt.csv\", index=False)\n",
    "    print(\"Scraping completed. Data saved to 'u.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 0 processed successfully.\n",
      "Page 1 processed successfully.\n",
      "Page 2 processed successfully.\n",
      "Page 3 processed successfully.\n",
      "Page 4 processed successfully.\n",
      "Page 5 processed successfully.\n",
      "Page 6 processed successfully.\n",
      "Page 7 processed successfully.\n",
      "Page 8 processed successfully.\n",
      "Page 9 processed successfully.\n",
      "Page 10 processed successfully.\n",
      "Page 11 processed successfully.\n",
      "Page 12 processed successfully.\n",
      "Page 13 processed successfully.\n",
      "Page 14 processed successfully.\n",
      "Page 15 processed successfully.\n",
      "Page 16 processed successfully.\n",
      "Page 17 processed successfully.\n",
      "Page 18 processed successfully.\n",
      "Page 19 processed successfully.\n",
      "Page 20 processed successfully.\n",
      "Page 21 processed successfully.\n",
      "Page 22 processed successfully.\n",
      "Page 23 processed successfully.\n",
      "Page 24 processed successfully.\n",
      "Page 25 processed successfully.\n",
      "Page 26 processed successfully.\n",
      "Page 27 processed successfully.\n",
      "Page 28 processed successfully.\n",
      "Page 29 processed successfully.\n",
      "Page 30 processed successfully.\n",
      "Page 31 processed successfully.\n",
      "Page 32 processed successfully.\n",
      "Page 33 processed successfully.\n",
      "Page 34 processed successfully.\n",
      "Page 35 processed successfully.\n",
      "Page 36 processed successfully.\n",
      "Page 37 processed successfully.\n",
      "Page 38 processed successfully.\n",
      "Page 39 processed successfully.\n",
      "Page 40 processed successfully.\n",
      "Page 41 processed successfully.\n",
      "Page 42 processed successfully.\n",
      "Page 43 processed successfully.\n",
      "Page 44 processed successfully.\n",
      "Page 45 processed successfully.\n",
      "Page 46 processed successfully.\n",
      "Page 47 processed successfully.\n",
      "Page 48 processed successfully.\n",
      "Page 49 processed successfully.\n",
      "Page 50 processed successfully.\n",
      "Page 51 processed successfully.\n",
      "Page 52 processed successfully.\n",
      "Page 53 processed successfully.\n",
      "Page 54 processed successfully.\n",
      "Page 55 processed successfully.\n",
      "Page 56 processed successfully.\n",
      "Page 57 processed successfully.\n",
      "Page 58 processed successfully.\n",
      "Page 59 processed successfully.\n",
      "Page 60 processed successfully.\n",
      "Page 61 processed successfully.\n",
      "Page 62 processed successfully.\n",
      "Page 63 processed successfully.\n",
      "Page 64 processed successfully.\n",
      "Page 65 processed successfully.\n",
      "Page 66 processed successfully.\n",
      "Page 67 processed successfully.\n",
      "Page 68 processed successfully.\n",
      "Page 69 processed successfully.\n",
      "Page 70 processed successfully.\n",
      "Page 71 processed successfully.\n",
      "Page 72 processed successfully.\n",
      "Page 73 processed successfully.\n",
      "Page 74 processed successfully.\n",
      "Page 75 processed successfully.\n",
      "Page 76 processed successfully.\n",
      "Page 77 processed successfully.\n",
      "Page 78 processed successfully.\n",
      "Page 79 processed successfully.\n",
      "Page 80 processed successfully.\n",
      "Page 81 processed successfully.\n",
      "Page 82 processed successfully.\n",
      "Page 83 processed successfully.\n",
      "Page 84 processed successfully.\n",
      "Page 85 processed successfully.\n",
      "Page 86 processed successfully.\n",
      "Page 87 processed successfully.\n",
      "Page 88 processed successfully.\n",
      "Page 89 processed successfully.\n",
      "Page 90 processed successfully.\n",
      "Page 91 processed successfully.\n",
      "Page 92 processed successfully.\n",
      "Page 93 processed successfully.\n",
      "Page 94 processed successfully.\n",
      "Page 95 processed successfully.\n",
      "Page 96 processed successfully.\n",
      "Page 97 processed successfully.\n",
      "Page 98 processed successfully.\n",
      "Page 99 processed successfully.\n",
      "Scraping completed. Data saved to 'u.csv'.\n"
     ]
    }
   ],
   "source": [
    "scrape_jobs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This script scrapes job postings from Wuzzuf.net and saves the data to a CSV file.\n",
    "# It handles pagination and potential errors during the scraping process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
