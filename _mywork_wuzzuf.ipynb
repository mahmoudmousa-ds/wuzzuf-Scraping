{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ef39254",
   "metadata": {},
   "source": [
    "# packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "ac30b176",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv \n",
    "import pandas as pd\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fe09ce",
   "metadata": {},
   "source": [
    "## inversting websites data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "f1bfb214",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://wuzzuf.net/search/jobs/?a=hpb%7Cspbg&q=data%20science&start=0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "ac104d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "b739906a",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(response.text,\"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b1dd10",
   "metadata": {},
   "source": [
    "###  Let's Get all jobs using the div idea --> But what is the css-pkv5jc!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "ba92f321",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_jobs=soup.find_all(\"div\",attrs={\"class\":\"css-pkv5jc\"})\n",
    "len(all_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "7b15aa3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Experienced'"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_jobs[2].find_all(\"a\")[4].get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "4e51c825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Full Time'"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_jobs[2].find_all(\"a\")[3].get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "8494c5c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' · Engineering - Telecom/Technology'"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_jobs[2].find_all(\"a\")[6].get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "ddd8d657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Showing 1 - 15 of 481'"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_number=soup.find(\"li\",attrs={\"class\":\"css-8neukt\"}).get_text()\n",
    "job_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "2b93afa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(job_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "40d31fd0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Showing 1 - 15 of 481'"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_number.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "02b925cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "text = \"Showing 1 - 15 of 481\"\n",
    "number = re.search(r'\\d+', job_number).group()\n",
    "print(number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "ee9afc00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find method return only index of exist text\n",
    "job_number.find(\"15\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "2a16a5b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find method return only index of exist text and if it's not exist return -1\n",
    "job_number.find(\"18\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "a03d10cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "text = \"Showing 1 - 15 of 481\"\n",
    "number = re.search(r'\\d+', text).group()\n",
    "print(number)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "7cdf7761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "481\n"
     ]
    }
   ],
   "source": [
    "number = int(text.split()[-1])\n",
    "print(number)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "d6c23d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "div1=all_jobs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "c170ac6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"https://wuzzuf.net/jobs/careers/Ejada--Cairo--Egypt-9273\" rel=\"noreferrer\" target=\"_blank\"></a>,\n",
       " <a class=\"css-o171kl\" href=\"/jobs/p/jNlWAq0DOr9n-Data-Analyst---in-KSA-Ejada-Cairo-Egypt?o=2&amp;l=sp&amp;t=sj&amp;a=data science|search-v3|hpb|spbg\" rel=\"noreferrer\" target=\"_blank\">Data Analyst - in KSA</a>,\n",
       " <a class=\"css-17s97q8\" href=\"https://wuzzuf.net/jobs/careers/Ejada--Cairo--Egypt-9273\" rel=\"noreferrer\" target=\"_blank\">Ejada  -</a>,\n",
       " <a class=\"css-n2jc4m\" href=\"/a/Full-Time-Jobs-in-Egypt\"><span class=\"css-1ve4b75 eoyjyou0\">Full Time</span></a>,\n",
       " <a class=\"css-o171kl\" href=\"/a/Experienced-Jobs-in-Egypt\">Experienced</a>,\n",
       " <a class=\"css-o171kl\" href=\"/a/IT-Software-Development-Jobs-in-Egypt\"> <!-- -->· <!-- -->IT/Software Development</a>,\n",
       " <a class=\"css-5x9pm1\" href=\"/a/Data-Analysis-Jobs-in-Egypt\"><span><strong class=\"highlight\">Data</strong><span> Analysis</span></span></a>,\n",
       " <a class=\"css-5x9pm1\" href=\"/a/Data-Analyst-Jobs-in-Egypt\"><span><strong class=\"highlight\">Data</strong><span> Analyst</span></span></a>,\n",
       " <a class=\"css-5x9pm1\" href=\"/a/Computer-Science-Jobs-in-Egypt\"><span><span>Computer </span><strong class=\"highlight\">Science</strong></span></a>,\n",
       " <a class=\"css-5x9pm1\" href=\"/a/SQL-Jobs-in-Egypt\"> <!-- -->· <!-- -->SQL</a>,\n",
       " <a class=\"css-5x9pm1\" href=\"/a/Statistics-Jobs-in-Egypt\"> <!-- -->· <!-- -->Statistics</a>]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "div1.find_all(\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "83295d51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/jobs/p/jNlWAq0DOr9n-Data-Analyst---in-KSA-Ejada-Cairo-Egypt?o=2&l=sp&t=sj&a=data science|search-v3|hpb|spbg'"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link_tag=div1.find(\"a\",attrs={\"class\":\"css-o171kl\",\"target\":\"_blank\"})[\"href\"]\n",
    "link_tag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "80f61c15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://wuzzuf.net/jobs/p/jNlWAq0DOr9n-Data-Analyst---in-KSA-Ejada-Cairo-Egypt?o=2&l=sp&t=sj&a=data science|search-v3|hpb|spbg'"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_link = \"https://wuzzuf.net\"+ link_tag\n",
    "actual_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "bb9b1692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data Analyst - in KSA'"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title=div1.find(\"a\",attrs={\"class\":\"css-o171kl\",\"target\":\"_blank\"}).get_text()\n",
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "ea019acc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cairo, Egypt '"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location=div1.find(\"span\",{\"class\":\"css-5wys0k\"}).get_text()\n",
    "location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "d557b312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Full TimeExperienced · 3 - 5 Yrs of Exp · IT/Software Development · Data Analysis · Data Analyst · Computer Science · SQL · Statistics'"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description=div1.find(\"div\",attrs={\"class\":\"css-y4udm8\"}).get_text()\n",
    "description\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "98ef360a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ejada  -'"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_name=div1.find(\"a\",attrs={\"target\":\"_blank\",\"class\":\"css-17s97q8\"}).get_text()\n",
    "company_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "77eb2c2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Showing 1 - 15 of 481'"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "193a7c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# l2=[j.get_text() for j in soup.find_all(\"h2\")]    \n",
    "# loc=[loc.get_text()for loc in soup.find_all(\"span\",{\"class\":\"css-5wys0k\"})]\n",
    "\n",
    "# print(l2)\n",
    "# print(loc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "ba663d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_links=[]\n",
    "titles=[]\n",
    "locations=[]\n",
    "skills=[]\n",
    "companies=[]\n",
    "data=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "656dcf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "page_number=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "c7e89c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now Going to Scrap next page 1\n",
      "Now Going to Scrap next page 2\n",
      "Now Going to Scrap next page 3\n",
      "Now Going to Scrap next page 4\n",
      "Now Going to Scrap next page 5\n",
      "Now Going to Scrap next page 6\n",
      "Now Going to Scrap next page 7\n",
      "Now Going to Scrap next page 8\n",
      "Now Going to Scrap next page 9\n",
      "Now Going to Scrap next page 10\n",
      "Now Going to Scrap next page 11\n",
      "Now Going to Scrap next page 12\n",
      "Now Going to Scrap next page 13\n",
      "Now Going to Scrap next page 14\n",
      "Now Going to Scrap next page 15\n",
      "Now Going to Scrap next page 16\n",
      "Now Going to Scrap next page 17\n",
      "Now Going to Scrap next page 18\n",
      "Now Going to Scrap next page 19\n",
      "Now Going to Scrap next page 20\n",
      "Now Going to Scrap next page 21\n",
      "Now Going to Scrap next page 22\n",
      "Now Going to Scrap next page 23\n",
      "Now Going to Scrap next page 24\n",
      "Now Going to Scrap next page 25\n",
      "Now Going to Scrap next page 26\n",
      "Now Going to Scrap next page 27\n",
      "Now Going to Scrap next page 28\n",
      "Now Going to Scrap next page 29\n",
      "Now Going to Scrap next page 30\n",
      "Now Going to Scrap next page 31\n",
      "Now Going to Scrap next page 32\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    results = requests.get(f'https://wuzzuf.net/search/jobs/?a=hpb%7Cspbg&q=data%20science&start={page_number}')\n",
    "    soup=BeautifulSoup(results.content,\"html.parser\")\n",
    "    all_jobs=soup.find_all(\"div\",attrs={\"class\":\"css-pkv5jc\"})\n",
    "    job_number=soup.find(\"li\",attrs={\"class\":\"css-8neukt\"}).text\n",
    "    for job in all_jobs:\n",
    "        link = \"https://wuzzuf.net\" +job.find(\"a\",attrs={\"class\":\"css-o171kl\",\"target\":\"_blank\"})[\"href\"]\n",
    "        title=job.find(\"a\",attrs={\"class\":\"css-o171kl\",\"target\":\"_blank\"}).get_text()\n",
    "        location = job.find('span', attrs = {'class' : 'css-5wys0k'}).get_text()\n",
    "        description = job.find('div', attrs = {'class' : 'css-y4udm8'}).get_text()\n",
    "        company_name = job.find('a', attrs = {'target' : \"_blank\", 'class' : 'css-17s97q8'}).get_text()\n",
    "        job_links.append(link)\n",
    "        titles.append(title)\n",
    "        locations.append(location)\n",
    "        skills.append(description)\n",
    "        companies.append(company_name)\n",
    "        d=[link,title,location,description,company_name]\n",
    "        data.append(d)\n",
    "        #notice that 30 to not scrap all pages and wuzzuf doesn't figure out that you scrapiing\n",
    "    if job_number[:-3].find(\"481\") == -1:\n",
    "        page_number += 1\n",
    "        print(\"Now Going to Scrap next page\",page_number)\n",
    "    else: \n",
    "        print(\"Finished\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "01da496a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Showing 481 - 481 of '"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_number[:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "a638bd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Don't we want to iterate forever until we get all pages! \n",
    "# ### Then we need a starting page number & white true\n",
    "\n",
    "# page_number = 0\n",
    "\n",
    "# while True :\n",
    "#     ### Let's read the webpage and iterate over it\n",
    "#     results = requests.get(f'https://wuzzuf.net/search/jobs/?a=hpb%7Cspbg&q=data%20science&start={page_number}')\n",
    "    \n",
    "#     ### Let's Init an Object for the new content read everytime\n",
    "#     soup = BeautifulSoup(results.content, 'html.parser')\n",
    "    \n",
    "#     ### Reading All jobs like we have done before using their div & style\n",
    "#     all_jobs = soup.find_all('div', attrs= {'class' : 'css-pkv5jc'})\n",
    "    \n",
    "#     ### Reading Job Number like we have done before\n",
    "#     job_number = soup.find('li', attrs = {'class' : 'css-8neukt'}).text\n",
    "    \n",
    "#     ### Having All Jobs in a variable it's time to iterate over job job!\n",
    "#     ### Just like we have done before accessing list items\n",
    "#     for job in all_jobs :\n",
    "    \n",
    "#         link = 'https://wuzzuf.net' + job.find('a', attrs = {'target' : \"_blank\", 'class' : 'css-o171kl'})['href']\n",
    "#         title = job.find('a', attrs = {'target' : \"_blank\", 'class' : 'css-o171kl'}).get_text()\n",
    "#         location = job.find('span', attrs = {'class' : 'css-5wys0k'}).get_text()\n",
    "#         description = job.find('div', attrs = {'class' : 'css-y4udm8'}).get_text()\n",
    "#         company_name = job.find('a', attrs = {'target' : \"_blank\", 'class' : 'css-17s97q8'}).get_text()\n",
    "        \n",
    "        \n",
    "#         ### Let's Append every item we have inside it's previously created empty list\n",
    "#         ### You May need to use it later or in other tasks!\n",
    "#         job_links.append('https://wuzzuf.net/' + link)\n",
    "#         titles.append(title)\n",
    "#         locations.append(location)\n",
    "#         skills.append(description)\n",
    "#         companies.append(company_name)\n",
    "        \n",
    "#         ### Let's also append all of these list into another big list\n",
    "#         ### List of lists --> You will know why later on!\n",
    "#         d = [link, title, location, description, company_name]\n",
    "#         data.append(d)  \n",
    "        \n",
    "#     ### Let's Increment the page number as long as we didn't reach the last job!\n",
    "#     ### Else Print Finished and break the code.\n",
    "#     if job_number[:-3].find('50') == -1 :\n",
    "#         page_number += 1\n",
    "#         print(\"Now Going to Scrap Page Number = \",page_number)\n",
    "#     else :\n",
    "#         print(\"Finished\")\n",
    "#         break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa4862f",
   "metadata": {},
   "source": [
    "### Assemble All The Data Inside a CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "dcbce59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Let's Add Everything to the CSV File like we have done before.\n",
    "with open(\"jobs_2_April_2023.csv\", 'w', newline = \"\", encoding = 'UTF-8') as f :\n",
    "    writer = csv.writer(f)\n",
    "    header = [\"link\", \"title\", \"location\", \"description\", \"company_name\"]\n",
    "    writer.writerow(header)\n",
    "    writer.writerows(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37500e07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ff5a40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2787d39c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126cd6e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5151d92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ec648f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
